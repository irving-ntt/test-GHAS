import os
import re

from logger import logger
from pyspark.sql import SparkSession
from pyspark.sql.types import ArrayType, StringType, StructField, StructType

from databricks.sdk.runtime import dbutils


class QueryManager:
    """
    Clase para manejar consultas SQL dentro de la carpeta 'SQL' y procesar sus par√°metros.
    """

    def __init__(self):
        """
        Constructor de QueryManager. Carga autom√°ticamente la lista de archivos SQL
        y sus par√°metros en el objeto.
        """
        self.sql_path_dbfs = self._get_sql_folder_path()
        self.queries = self._get_sql_list()

    def _get_sql_folder_path(self):
        """
        Obtiene la ruta de la carpeta SQL.
        """
        try:
            notebook_path = (
                dbutils.notebook.entry_point.getDbutils()
                .notebook()
                .getContext()
                .notebookPath()
                .get()
            )
        except Exception as e:
            raise RuntimeError(
                f"No se pudo obtener el path del notebook. Error: {str(e)}"
            )

        path_parts = notebook_path.split("/")
        if "Notebooks" not in path_parts:
            raise FileNotFoundError(
                f"La carpeta 'Notebooks' no se encontr√≥ en el path: {notebook_path}"
            )

        notebooks_index = path_parts.index("Notebooks")
        base_dir = "/".join(path_parts[:notebooks_index])  # Directorio ra√≠z

        return f"/Workspace{base_dir}/SQL"

    def _get_sql_list(self):
        """
        Obtiene la lista de archivos SQL en la carpeta 'SQL' y extrae los par√°metros.

        :return: DataFrame de PySpark con:
                 - "Archivo SQL": Nombre del archivo SQL.
                 - "Par√°metros": Lista de par√°metros detectados dentro de ##.
        """
        spark = SparkSession.getActiveSession()

        if not os.path.exists(self.sql_path_dbfs):
            logger.warning(f"La carpeta 'SQL' no existe en {self.sql_path_dbfs}")
            empty_schema = StructType(
                [
                    StructField("Archivo SQL", StringType(), True),
                    StructField("Par√°metros", ArrayType(StringType()), True),
                ]
            )
            return spark.createDataFrame([], schema=empty_schema)

        sql_files = [f for f in os.listdir(self.sql_path_dbfs) if f.endswith(".sql")]

        if not sql_files:
            logger.warning(f"No se encontraron archivos .sql en {self.sql_path_dbfs}")
            empty_schema = StructType(
                [
                    StructField("Archivo SQL", StringType(), True),
                    StructField("Par√°metros", ArrayType(StringType()), True),
                ]
            )
            return spark.createDataFrame([], schema=empty_schema)

        # Crear la lista de tuplas (archivo, par√°metros extra√≠dos)
        files_with_params = [
            (file, self._extract_parameters(os.path.join(self.sql_path_dbfs, file)))
            for file in sql_files
        ]

        # Definir el esquema expl√≠citamente para evitar errores de inferencia de tipos
        schema = StructType(
            [
                StructField("Archivo SQL", StringType(), True),
                StructField("Par√°metros", ArrayType(StringType()), True),
            ]
        )

        return spark.createDataFrame(files_with_params, schema)

    @staticmethod
    def _extract_parameters(file_path):
        """
        M√©todo interno para leer un archivo SQL y extraer los par√°metros dentro de ##.

        :param file_path: Ruta completa del archivo SQL.
        :return: Lista de par√°metros encontrados en el archivo.
        """
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                params = re.findall(
                    r"#(.*?)#", content
                )  # Buscar par√°metros dentro de ##
                return params
        except Exception as e:
            logger.warning(f"No se pudo leer {file_path}. Error: {e}")
            return []

    def get_sql_list(self):
        """
        Devuelve la lista de archivos SQL y sus par√°metros detectados.

        :return: DataFrame de PySpark con:
                 - "Archivo SQL"
                 - "Par√°metros"
        """
        return self.queries

    def get_statement(self, sql_filename, hints=None, **params):
        """
        Carga un archivo SQL y reemplaza los par√°metros dentro de ## con los valores proporcionados.
        Tambi√©n permite agregar hints SQL opcionales para SELECT, DELETE, INSERT y UPDATE.

        :param sql_filename: Nombre del archivo SQL.
        :param hints: Hints SQL opcionales.
        :param params: Diccionario de valores para reemplazar en el query.
        :return: Query con los par√°metros reemplazados.
        """
        sql_path = os.path.join(self.sql_path_dbfs, sql_filename)

        if not os.path.exists(sql_path):
            raise FileNotFoundError(
                f"El archivo {sql_filename} no existe en la carpeta SQL."
            )

        try:
            with open(sql_path, "r", encoding="utf-8") as f:
                query = f.read()

                # Reemplazar par√°metros dentro de ## con los valores proporcionados
                for key, value in params.items():
                    query = query.replace(f"#{key}#", str(value))

                # Insertar hint seg√∫n el tipo de query
                if hints:
                    query = self._insert_hints(query, hints)

                print("\nüìú **Query generado:**\n")
                print(query)  # Se imprimir√° autom√°ticamente el query formateado

                return query
        except Exception as e:
            raise RuntimeError(f"No se pudo leer o procesar {sql_filename}. Error: {e}")

    @staticmethod
    def _insert_hints(query, hints):
        """
        Inserta hints en la posici√≥n correcta seg√∫n el tipo de query.

        :param query: Query original.
        :param hints: Hints SQL opcionales.
        :return: Query modificado con los hints aplicados correctamente.
        """
        # Para SELECT - buscar en cualquier l√≠nea, no solo al inicio
        if re.search(r"(?i)\bSELECT\b", query):
            return re.sub(r"(?i)\bSELECT\b", f"SELECT {hints}", query, count=1)

        # Para DELETE ‚Üí Insertar hint justo despu√©s de DELETE
        if re.search(r"(?i)\bDELETE\s+FROM\b", query):
            return re.sub(r"(?i)\b(DELETE)", rf"\1 {hints}", query, count=1)

        # Para UPDATE
        if re.search(r"(?i)\bUPDATE\b", query):
            return re.sub(r"(?i)\b(UPDATE\s+\w+)", rf"\1 {hints}", query, count=1)

        # Para INSERT
        if re.search(r"(?i)\bINSERT\s+INTO\b", query):
            return re.sub(
                r"(?i)\b(INSERT\s+INTO\s+\w+)", rf"\1 {hints}", query, count=1
            )

        return query  # Si no coincide con ninguna regla, se deja sin cambios
